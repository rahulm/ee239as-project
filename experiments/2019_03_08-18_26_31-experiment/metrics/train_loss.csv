epoch,train_loss
0,11.281105
1,8.539404
2,6.337644
3,4.611331
4,3.300680
5,2.333486
6,1.650691
7,1.207307
8,0.952974
9,0.815063
10,0.748890
11,0.719249
12,0.703808
13,0.694280
14,0.689174
15,0.686099
16,0.683679
17,0.681889
18,0.680728
19,0.679187
20,0.678208
21,0.676899
22,0.675443
23,0.674128
24,0.673370
25,0.672100
26,0.670671
27,0.669852
28,0.668677
29,0.667686
30,0.666788
31,0.665529
32,0.664430
33,0.663309
34,0.662605
35,0.661441
36,0.660703
37,0.659501
38,0.658631
39,0.657545
40,0.657160
41,0.655738
42,0.654743
43,0.653862
44,0.653001
45,0.652422
46,0.651352
47,0.651116
48,0.650122
49,0.649155
50,0.649140
51,0.647113
52,0.646650
53,0.646229
54,0.644880
55,0.644908
56,0.643671
57,0.643240
58,0.641996
59,0.641392
60,0.640829
61,0.639737
62,0.639444
63,0.638754
64,0.638022
65,0.637071
66,0.636635
67,0.636585
68,0.635555
69,0.634931
70,0.633954
71,0.633531
72,0.633146
73,0.632052
74,0.631915
75,0.631286
76,0.630717
77,0.630675
78,0.628964
79,0.628638
80,0.627908
81,0.627636
82,0.627121
83,0.626225
84,0.625701
85,0.625368
86,0.624916
87,0.624554
88,0.623742
89,0.623012
90,0.622973
91,0.622663
92,0.621750
93,0.620999
94,0.620761
95,0.620857
96,0.619528
97,0.619722
98,0.619341
99,0.619160
